{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 重要度算出するやつ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from minepy import MINE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class calculate_importance():\n",
    "    \n",
    "    def __new__(self):\n",
    "        '''\n",
    "        イニシャライザ\n",
    "        \n",
    "        all_rf_importance (pandas.DataFrame): ランダムフォレストの重要度を格納するdataframe\n",
    "        all_etr_importance (pandas.DataFrame): extratreesregressorの重要度を格納するdataframe\n",
    "        all_rf_importance (pandas.DataFrame): ランダムフォレストの重要度を格納するdataframe\n",
    "        all_rf_importance (pandas.DataFrame): ランダムフォレストの重要度を格納するdataframe\n",
    "        '''\n",
    "        self.all_rf_importance = pd.DataFrame()\n",
    "        self.all_etr_importance = pd.DataFrame()\n",
    "        self.all_mic = pd.DataFrame()\n",
    "        self.all_corr = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    def __init__(self, variables, purpose):\n",
    "        '''\n",
    "        目的変数に対する重要度や相関係数を算出するクラス\n",
    "\n",
    "        Args:\n",
    "            variables (pandas.DataFrame): 説明変数を格納したdataframe\n",
    "            purpose (pandas.DataFrame): 目的変数を格納したdataframe\n",
    "        '''\n",
    "        # 特徴量と目的変数に分ける\n",
    "        X = variables.copy()\n",
    "        y = purpose.copy()\n",
    "\n",
    "        # 特徴量名を取り出しておく\n",
    "        feature_x = X.columns\n",
    "\n",
    "        for column in y.columns:\n",
    "            print(column)\n",
    "            rf_importance = self.__calculate_rf_importance(X, y[column])\n",
    "            print(\" rf\")\n",
    "            etr_importance = self.__calculate_etr_importance(X, y[column])\n",
    "            print(\" etr\")\n",
    "            mic_list = self.__mic_calculation(X, y[column])\n",
    "            print(\" mic\")\n",
    "            corr_list = self.__corr_calculation(X, y[column])\n",
    "            print(\" corr\")\n",
    "\n",
    "            rf_importance = pd.Series(rf_importance, index=feature_x, name=column)\n",
    "            etr_importance = pd.Series(etr_importance, index=feature_x, name=column)\n",
    "            mic = pd.Series(mic_list, index=feature_x, name=column)\n",
    "            corr = pd.Series(corr_list, index=feature_x, name=column)\n",
    "\n",
    "            self.all_corr = pd.concat([self.all_corr, corr], axis=1, sort=False)\n",
    "            self.all_mic = pd.concat([self.all_mic, mic], axis=1, sort=False)\n",
    "            self.all_rf_importance = pd.concat([self.all_rf_importance, rf_importance], axis=1, sort=False)\n",
    "            self.all_etr_importance = pd.concat([self.all_etr_importance, etr_importance], axis=1, sort=False)\n",
    "        self.all_corr = self.all_corr.fillna(0)\n",
    "\n",
    "\n",
    "    def __calculate_rf_importance(self, X, y):\n",
    "        '''\n",
    "        目的変数に対する説明変数の需要度を算出する\n",
    "\n",
    "        Args:\n",
    "            X (pandas.DataFrame): 説明変数を格納したdataframe\n",
    "            y (pandas.Series): 目的変数を格納したSeries\n",
    "        Return:\n",
    "            \n",
    "        '''\n",
    "        reg_rf = RandomForestRegressor(random_state=0, n_estimators=100)\n",
    "        reg_rf.fit(X=X, y=y)\n",
    "        return reg_rf.feature_importances_\n",
    "\n",
    "\n",
    "    def __calculate_etr_importance(self, X, y):\n",
    "        '''\n",
    "        目的変数に対する説明変数の需要度を算出する\n",
    "\n",
    "        Args:\n",
    "            X (pandas.DataFrame): 説明変数を格納したdataframe\n",
    "            y (pandas.Series): 目的変数を格納したSeries\n",
    "        '''\n",
    "        reg_etr = ExtraTreesRegressor(random_state=0, n_estimators=100)\n",
    "        reg_etr.fit(X=X, y=y)\n",
    "        return reg_etr.feature_importances_\n",
    "\n",
    "\n",
    "    def __mic_calculation(self, X, y):\n",
    "        '''\n",
    "        目的変数に対する説明変数の非線形相関係数を算出する\n",
    "\n",
    "        Args:\n",
    "            X (pandas.DataFrame): 説明変数を格納したdataframe\n",
    "            y (pandas.Series): 目的変数を格納したSeries\n",
    "        '''\n",
    "        mine = MINE()\n",
    "        mic_list = np.array([])\n",
    "        for n, column in enumerate(X.columns):\n",
    "            mine.compute_score(y, X[column])\n",
    "            mic_list = np.append(mic_list, mine.mic())\n",
    "        return mic_list\n",
    "\n",
    "\n",
    "    def __corr_calculation(self,X, y):\n",
    "        '''\n",
    "        目的変数に対する説明変数の相関係数を算出する\n",
    "\n",
    "        Args:\n",
    "            X (pandas.DataFrame): 説明変数を格納したdataframe\n",
    "            y (pandas.Series): 目的変数を格納したSeries\n",
    "        '''\n",
    "        corr_list = np.array([])\n",
    "        for n, column in enumerate(X.columns):\n",
    "            np.seterr(divide='ignore', invalid='ignore')\n",
    "            corr_list = np.append(corr_list, np.corrcoef(y, X[column])[0,1])\n",
    "        return corr_list\n",
    "\n",
    "\n",
    "    def rank_feature(self, output_name):\n",
    "        '''\n",
    "        総関係数や重要度から算出したスコアで説明変数に順位をつける\n",
    "\n",
    "        Args:\n",
    "            output_name (String): 保存するエクセルのファイル名\n",
    "        '''\n",
    "            corr = self.all_corr\n",
    "            mic = self.all_mic\n",
    "            rf = self.all_rf_importance\n",
    "            etr = self.all_etr_importance\n",
    "            writer = pd.ExcelWriter(f\"../output/{datetime.datetime.today().strftime('%Y%m%d%H')}_{output_name}\")\n",
    "            for column in corr.columns:\n",
    "                print(column)\n",
    "                rank = pd.DataFrame(index=corr.index)\n",
    "                rank[\"corr_rank\"] = corr[column].abs().apply(lambda x: 5 if x > 0.6 else 4 if x > 0.4 else 3 if x > 0.25 else 2 if x > 0.16 else 1)\n",
    "                rank[\"corr\"] = corr[column]\n",
    "                rank[\"mic_rank\"] = mic[column].apply(lambda x: 5 if x > 0.6 else 4 if x > 0.4 else 3 if x > 0.25 else 2 if x > 0.16 else 1)\n",
    "                rank[\"mic\"] = mic[column]\n",
    "                rank[\"rf_rank\"] = rank_importance(rf, column).astype(\"int\")\n",
    "                rank[\"rf\"] = rf[column]\n",
    "                rank[\"etr_rank\"] = rank_importance(etr, column).astype(\"int\")\n",
    "                rank[\"etr\"] = rf[column]\n",
    "                rank_index = [column for column in corr.index]\n",
    "                rank = rank.loc[rank_index][[\"corr\", \"mic\", \"rf\", \"etr\"]].abs()\n",
    "                mm = preprocessing.MinMaxScaler()\n",
    "                rank = pd.DataFrame(mm.fit_transform(rank), index=rank.index, columns=rank.columns)\n",
    "                rank[\"score\"] = rank.apply(lambda x: x[\"corr\"]+x[\"mic\"]+x[\"rf\"]+x[\"etr\"], axis=1)\n",
    "                rank[\"score\"] = rank[\"score\"].rank(ascending=False)\n",
    "                rank.to_excel(writer, sheet_name=column)\n",
    "                writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# クロス集計とかカイ二乗検定するやつ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cvx():\n",
    "    \n",
    "    def __init__(self, variables, purpose, split_num=5):\n",
    "        self.variables = variables\n",
    "        self.purpose = purpose\n",
    "        self.split_num = split_num\n",
    "        \n",
    "        \n",
    "    def calculate_x2(self, purpose, variables, purpose_type):\n",
    "        purpose_columns = [column for column in purpose.columns if purpose_type in column]\n",
    "        df_list = []\n",
    "        for p_column in purpose_columns:\n",
    "            all_x2_df = self.__x2_calculate(p_column)\n",
    "            all_cross_df = self.__crosstab(p_column)\n",
    "            df_list.append(pd.concat([all_cross_df, all_x2_df], axis=1, sort=False))\n",
    "        return df_list\n",
    "\n",
    "    \n",
    "    def self.__crosstab(self, p_column):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        all_cross_df = pd.DataFrame()\n",
    "        for v_column in self.variables.columns:\n",
    "            df_list = self.__split_dataframe(self.variables, v_column, self.split_num) # variablesをsplit_num個に分割する\n",
    "            p_num = len(self.purpose[p_column].unique())\n",
    "            if p_num==2: # 目的変数が２値データの場合\n",
    "                cross_df = pd.DataFrame(index=[0, 1])\n",
    "                for i in range(self.split_num):\n",
    "                    length = len(self.purpose.loc[df_list[i].index])\n",
    "                    cross_aggregation = self.purpose.loc[df_list[i].index][p_column].value_counts() / length\n",
    "                    cross_aggregation.name = f\"カテゴリ{i}\"\n",
    "                    cross_df = pd.concat([cross_df, (cross_aggregation)], axis=1, sort=False)\n",
    "                cross_df = cross_df.fillna(0)\n",
    "                cross_df.index = [f\"{v_column}\" for index in cross_df.index]\n",
    "                all_cross_df = all_cross_df.append(cross_df.iloc[1])\n",
    "            elif p_num>2: # 目的変数が連続値データの場合\n",
    "                cross_list = []\n",
    "                cross_df = pd.DataFrame()\n",
    "                column_list = []\n",
    "                for i in range(self.split_num):\n",
    "                    cross_value = self.purpose.loc[df_list[i].index][p_column].sum()\n",
    "                    cross_list.append(cross_value)\n",
    "                    column_list.append(f\"カテゴリ{i}\")\n",
    "                cross_df = pd.DataFrame([cross_list], columns=column_list, index=[v_column])\n",
    "                all_cross_df = all_cross_df.append(cross_df)\n",
    "            else:\n",
    "                raise Purpose_num_error(p_column, p_num)\n",
    "        all_cross_df[\"平均\"] = all_cross_df[column_list].mean(axis=1)\n",
    "        all_cross_df[\"分散\"] = all_cross_df[column_list].var(axis=1)\n",
    "        all_cross_df = self.__date_5clastter(all_cross_df)\n",
    "        return all_cross_df\n",
    "\n",
    "\n",
    "    def __split_dataframe(self, data, column, n):\n",
    "        \"\"\"pandas.DataFrameのcolumn列を小さい順にソートして\n",
    "        n個に分割し、その分割したdataframeをリストに格納する。\n",
    "        \"\"\"\n",
    "        df = data[column].sort_values()\n",
    "        df_list = []\n",
    "        index_list = np.array_split(np.arange(len(df)), n)\n",
    "        for i in range(n):\n",
    "            df_list.append(df.iloc[index_list[i]])\n",
    "        return df_list\n",
    "\n",
    "\n",
    "    def __date_5clastter(self, df):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        mean_04 = df[[\"カテゴリ0\", \"カテゴリ4\"]].mean(axis=1).rename(\"平均_04\")\n",
    "        mean_123 = df[[\"カテゴリ1\", \"カテゴリ2\", \"カテゴリ3\"]].mean(axis=1).rename(\"平均_123\")\n",
    "        diff_40 = (df[\"カテゴリ4\"] - df[\"カテゴリ0\"]).rename(\"差分40\")\n",
    "\n",
    "        shape_df = pd.concat([df, mean_04, mean_123, diff_40], axis=1)\n",
    "        shape_list = []\n",
    "        for i, _ in enumerate(shape_df.index):\n",
    "            shape_df_ = shape_df.iloc[i]\n",
    "            try:\n",
    "                if (shape_df_[\"平均_123\"] > shape_df_[\"カテゴリ0\"]) & (shape_df_[\"平均_123\"] > shape_df_[\"カテゴリ4\"]):\n",
    "                    shape_list.append(\"山型\")\n",
    "                elif (shape_df_[\"平均_123\"] < shape_df_[\"カテゴリ0\"]) & (shape_df_[\"平均_123\"] < shape_df_[\"カテゴリ4\"]):\n",
    "                    shape_list.append(\"谷型\")\n",
    "                elif shape_df_[\"差分40\"] > 0:\n",
    "                    shape_list.append(\"右肩上がり\")\n",
    "                elif shape_df_[\"差分40\"] < 0:\n",
    "                    shape_list.append(\"右肩下がり\")\n",
    "                else:\n",
    "                    shape_list.append(\"特徴なし\")\n",
    "            except:\n",
    "                print(shape_df_)\n",
    "        df[\"データ分類\"] = shape_list\n",
    "        return df\n",
    "\n",
    "\n",
    "    def self.__x2_calculate(self,p_column):\n",
    "        x2_list = []\n",
    "        for v_column in self.variables.columns:\n",
    "            df_list = self.__split_dataframe(self.variables, v_column, self.split_num)\n",
    "            p_num = len(self.purpose[p_column].unique())\n",
    "            if p_num==2:\n",
    "                x2_df = pd.DataFrame(index=[0, 1])\n",
    "                for i in range(self.split_num):\n",
    "                    x2_aggregation = self.purpose.loc[df_list[i].index][p_column].value_counts()\n",
    "                    x2_aggregation.name = f\"{v_column}_カテゴリ{i}\"\n",
    "                    x2_df = pd.concat([x2_df, (x2_aggregation)], axis=1, sort=False)\n",
    "                x2_df = x2_df.fillna(0).T\n",
    "                try:\n",
    "                    x2, p, dof, expected = sp.stats.chi2_contingency(x2_df.values)\n",
    "                    x2_list.append(x2)\n",
    "                except:\n",
    "                    x2_list.append(np.nan)\n",
    "            elif p_num>2: # 目的変数が連続値データの場合\n",
    "                x2_posi_list = []\n",
    "                x2_neg_list = []\n",
    "                c_df=pd.DataFrame()\n",
    "                column_list = []\n",
    "                for i in range(self.split_num):\n",
    "                    x2_aggregation = self.purpose.loc[df_list[i].index][p_column].sum()\n",
    "                    x2_posi_list.append(x2_aggregation)\n",
    "                    x2_neg_list.append((len(self.purpose)*128*2/5)-x2_aggregation)\n",
    "                    column_list.append(f\"カテゴリ{i}\")\n",
    "                x2_df = pd.DataFrame([x2_posi_list, x2_neg_list], columns=column_list, index=[1, 0])\n",
    "                x2_df = x2_df.fillna(0).T\n",
    "                try:\n",
    "                    x2, p, dof, expected = sp.stats.chi2_contingency(x2_df.values)\n",
    "                    x2_list.append(x2)\n",
    "                except Exception as e:\n",
    "                    print(x2_df)\n",
    "                    raise e\n",
    "                    x2_list.append(np.nan)\n",
    "            else:\n",
    "                raise Purpose_num_error(p_column, p_num)\n",
    "        all_x2_df = pd.Series(x2_list, name=\"x2\", index=self.variables.columns)\n",
    "        return all_x2_df\n",
    "\n",
    "\n",
    "    def __rank_importance(self, df, column):\n",
    "        df = df.sort_values(column, ascending=False)\n",
    "        df[\"rank\"] = range(1, len(df)+1)\n",
    "        df[\"rank\"] = df[\"rank\"]/len(df)\n",
    "        df[\"rank\"] = df[\"rank\"].where(df[\"rank\"] > 0.1, 5)\n",
    "        df[\"rank\"] = df[\"rank\"].where(df[\"rank\"] > 0.2, 4)\n",
    "        df[\"rank\"] = df[\"rank\"].where(df[\"rank\"] > 0.3, 3)\n",
    "        df[\"rank\"] = df[\"rank\"].where(df[\"rank\"] > 0.4, 2)\n",
    "        df[\"rank\"] = df[\"rank\"].where(df[\"rank\"] > 2, 1)\n",
    "        return df[\"rank\"]\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_excel(dir_name, file_name, sheet_name = 0):\n",
    "    \"\"\"保存したpickleファイルの中で最新バージョンのものを取得する\n",
    "    \"\"\"\n",
    "    file_list = glob(f'.{os.path.sep}{dir_name}{os.path.sep}*[0-9]{10}_{file_name}', recursive=True)\n",
    "    file_list = [re.search(r'([0-9]{10})', i).group() for i in file_list ]\n",
    "    file_ver = max(file_list)\n",
    "    print(f'read:{file_ver}_{file_name}')\n",
    "    data = pd.read_excel(f'.{os.path.sep}{dir_name}{os.path.sep}{file_ver}_{file_name}', sheet_name = sheet_name)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# オリジナルエラークラス"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目的変数のユニーク数が１のときエラーを出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Purpose_num_error(IOError):\n",
    "        # Exceptionは、args属性を作るけど、このMyErrorでは、errorType,errorNumを作る\n",
    "    def __init__(self, column, p_num):\n",
    "        self.p_column=column\n",
    "        self.errorNum=p_num\n",
    "    def __str__(self):\n",
    "        return f'目的変数{self.p_column}のユニーク数が{self.errorNum}です'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目的変数nankaのユニーク数が1です\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    raise Purpose_num_error(\"nanka\",1)\n",
    "except Purpose_num_error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Purpose_num_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-896eab29de60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mraise\u001b[0m \u001b[0mPurpose_num_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nanka\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Purpose_num_error' is not defined"
     ]
    }
   ],
   "source": [
    "raise Purpose_num_error(\"nanka\",1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
